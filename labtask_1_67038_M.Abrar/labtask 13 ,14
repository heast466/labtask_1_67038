# =========================================================
# LOGISTIC REGRESSION ON diabetes.dat (ALL TASKS)
# =========================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sympy as sp
from scipy.optimize import curve_fit

# ---------- STEP 1: Load and clean diabetes.dat ----------
df = pd.read_csv("diabetes.dat", comment='@', header=None, delim_whitespace=True)

# Remove trailing commas and convert to float
for col in df.columns:
    df[col] = df[col].astype(str).str.replace(',', '').astype(float)

# First feature as X, last column as y
X = df.iloc[:, 0].values
y = df.iloc[:, -1].values

# ---------- STEP 2: Declare Logistic Function ----------
def logistic(x, b0, b1):
    return 1 / (1 + np.exp(-(b0 + b1 * x)))

# ---------- STEP 3: Plot Symbolic Logistic Function (SymPy) ----------
x = sp.symbols('x')
logistic_sympy = 1 / (1 + sp.exp(-(0 + 1*x)))  # example with b0=0, b1=1

sp.plot(
    logistic_sympy,
    (x, -10, 10),  # fixed range like you requested
    title="Logistic Function (SymPy)",
    xlabel="x",
    ylabel="f(x)"
)

# ---------- STEP 4: Fit Logistic Regression using SciPy ----------
params, _ = curve_fit(logistic, X, y, p0=[0,0])
b0_est, b1_est = params
print("Estimated Parameters:")
print("b0 =", b0_est)
print("b1 =", b1_est)

# ---------- STEP 5: Plot Fitted Logistic Curve ----------
x_vals = np.linspace(X.min(), X.max(), 300)
y_pred = logistic(x_vals, b0_est, b1_est)

plt.scatter(X, y, alpha=0.4, label="Actual Data")
plt.plot(x_vals, y_pred, color='red', linewidth=2, label="Fitted Logistic Curve")
plt.xlabel("Feature 1")
plt.ylabel("Probability of Diabetes")
plt.title("Logistic Regression on diabetes.dat")
plt.legend()
plt.show()




# =========================================================
# K-MEANS CLUSTERING AND RAND INDEX ON diabetes.dat
# =========================================================

import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.metrics import rand_score

# ---------- STEP 1: Load and clean diabetes.dat ----------
df = pd.read_csv("diabetes.dat", comment='@', header=None, delim_whitespace=True)

# Remove trailing commas and convert to float
for col in df.columns:
    df[col] = df[col].astype(str).str.replace(',', '').astype(float)

# Features (X) = all columns except last, Target (y) = last column
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values  # Binary target: 0 or 1

# ---------- STEP 2: Apply K-Means Clustering ----------
k = 2  # We know the target is binary
kmeans = KMeans(n_clusters=k, random_state=42)
clusters = kmeans.fit_predict(X)

# ---------- STEP 3: Compute Rand Index ----------
R = rand_score(y, clusters)

# ---------- STEP 4: Print results ----------
print("Cluster labels (unique):", np.unique(clusters))
print("Rand Index R =", R)

# Optional: visualize clustering (first 2 features only)
import matplotlib.pyplot as plt

plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', alpha=0.6)
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.title("K-Means Clustering on diabetes.dat")
plt.show()
